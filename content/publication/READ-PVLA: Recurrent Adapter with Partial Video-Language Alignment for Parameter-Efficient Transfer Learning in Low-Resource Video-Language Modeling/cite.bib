@article{nguyen_read-pvla_2024,
 abstract = {Fully fine-tuning pretrained large-scale transformer models has become a popular paradigm for video-language modeling tasks, such as temporal language grounding and videolanguage summarization. With a growing number of tasks and limited training data, such full fine-tuning approach leads to costly model storage and unstable training. To overcome these shortcomings, we introduce lightweight adapters to the pre-trained model and only update them at fine-tuning time. However, existing adapters fail to capture intrinsic temporal relations among video frames or textual words. Moreover, they neglect the preservation of critical task-related information that flows from the raw video-language input into the adapterâ€™s low-dimensional space. To address these issues, we first propose a novel REcurrent ADapter (READ) that employs recurrent computation to enable temporal modeling capability. Second, we propose Partial Video-Language Alignment (PVLA) objective via the use of partial optimal transport to maintain task-related information flowing into our READ modules. We validate our READ-PVLA framework through extensive experiments where READ-PVLA significantly outperforms all existing fine-tuning strategies on multiple low-resource temporal language grounding and video-language summarization benchmarks.},
 author = {Nguyen, Thong and Wu, Xiaobao and Dong, Xinshuai and Le, Khoi M. and Hu, Zhiyuan and Nguyen, Cong-Duy and Ng, See-Kiong and Luu, Anh Tuan},
 doi = {10.1609/aaai.v38i17.29847},
 file = {Nguyen et al. - 2024 - READ-PVLA Recurrent Adapter with Partial Video-La.pdf:files/5/Nguyen et al. - 2024 - READ-PVLA Recurrent Adapter with Partial Video-La.pdf:application/pdf},
 issn = {2374-3468, 2159-5399},
 journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
 language = {en},
 month = {March},
 number = {17},
 pages = {18824--18832},
 shorttitle = {READ-PVLA},
 title = {READ-PVLA: Recurrent Adapter with Partial Video-Language Alignment for Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling},
 url = {https://ojs.aaai.org/index.php/AAAI/article/view/29847},
 urldate = {2024-04-09},
 volume = {38},
 year = {2024}
}
